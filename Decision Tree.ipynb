{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "wine_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "wine_attributes = ['Class','Alcohol','Malic acid','Ash length','Alcalinity of ash', 'Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280','Proline']\n",
    "# first attribute is the class identifier (1-3)\n",
    "wine_df = pd.read_csv(wine_URL, names = wine_attributes)\n",
    "# Rearrange dataframe and switching target to the end of list\n",
    "cols = wine_df.columns.tolist() \n",
    "wine_df = wine_df[cols[1:]+cols[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash length</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid  Ash length  Alcalinity of ash  Magnesium  \\\n",
       "0      14.23        1.71        2.43               15.6        127   \n",
       "1      13.20        1.78        2.14               11.2        100   \n",
       "2      13.16        2.36        2.67               18.6        101   \n",
       "3      14.37        1.95        2.50               16.8        113   \n",
       "4      13.24        2.59        2.87               21.0        118   \n",
       "..       ...         ...         ...                ...        ...   \n",
       "173    13.71        5.65        2.45               20.5         95   \n",
       "174    13.40        3.91        2.48               23.0        102   \n",
       "175    13.27        4.28        2.26               20.0        120   \n",
       "176    13.17        2.59        2.37               20.0        120   \n",
       "177    14.13        4.10        2.74               24.5         96   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     Color intensity   Hue  OD280  Proline  Class  \n",
       "0               5.64  1.04   3.92     1065      1  \n",
       "1               4.38  1.05   3.40     1050      1  \n",
       "2               5.68  1.03   3.17     1185      1  \n",
       "3               7.80  0.86   3.45     1480      1  \n",
       "4               4.32  1.04   2.93      735      1  \n",
       "..               ...   ...    ...      ...    ...  \n",
       "173             7.70  0.64   1.74      740      3  \n",
       "174             7.30  0.70   1.56      750      3  \n",
       "175            10.20  0.59   1.56      835      3  \n",
       "176             9.30  0.60   1.62      840      3  \n",
       "177             9.20  0.61   1.60      560      3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining entropy and information gain functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is calculates using shannon's definition and information gain is the difference between entropy and split entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(target_attribute):\n",
    "    X , counts = np.unique(target_attribute, return_counts = True)\n",
    "    pX = [ci/len(target_attribute) for ci in counts]\n",
    "    entropy = -1*(pX@np.log2(pX))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_Entropy(Y,given): #H(Y|given)\n",
    "    result =  0\n",
    "    values, counts = np.unique(given, return_counts = True)\n",
    "    for v , c  in zip(values,counts):\n",
    "        splited_Y = [Y[i] for i in range(len(Y)) if given[i]==v]\n",
    "        H = Entropy(splited_Y)\n",
    "        p = c/len(given)\n",
    "        result += p*H  #-1*sum(p*H)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gain(X,given):\n",
    "    return Entropy(X) - conditional_Entropy(X,given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the decision tree node data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNode:\n",
    "    def __init__(self,name,parent=None,par_val=None):\n",
    "        self.name= name\n",
    "        self.parent = parent\n",
    "        self.children = [] #list of TNodes, if empty =>this node is a leaf\n",
    "        self.values = []\n",
    "        self.par_val = par_val\n",
    "        \n",
    " \n",
    "    def set_values(self,v):\n",
    "        self.values = list(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing attribute with maximum gain and implementing (ID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_gain_node(DataFrame):\n",
    "    features = list(DataFrame.columns)\n",
    "    feature_dic = {features[i]:Gain(list(DataFrame[features[i]]), list(DataFrame[features[-1]])) for i in range(0,len(features)-1)}\n",
    "    max_gain = max(feature_dic.values())\n",
    "    index_max = list(feature_dic.values()).index(max_gain)\n",
    "    winner_name = list(feature_dic.keys())[index_max]\n",
    "    winner_node = TNode(winner_name)\n",
    "    branches = np.unique(DataFrame[winner_name])\n",
    "    winner_node.set_values(branches)\n",
    "    return winner_node\n",
    "\n",
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count)\n",
    "               \n",
    "def ID3(df,depth=0, root=None):\n",
    "    if root==None: #Initialization\n",
    "        root = max_gain_node(df)\n",
    "    if root.parent:\n",
    "        if len(root.values)<len(root.parent.values):\n",
    "            depth =20\n",
    "    depth +=1\n",
    "    if depth < 20:# Maximum depth fixed to avoid over fitting and complex models             \n",
    "        for att in root.values:\n",
    "            child_df = df[df[root.name] == att]# Splitting dataset per specific attribute \n",
    "            child_df.drop(root.name,axis=1) # Removing the current attribute\n",
    "            remaining_class_labels = list(child_df[list(child_df.columns)[-1]])\n",
    "            child_labels = np.unique(remaining_class_labels) # Remaining Labels\n",
    "            if len(child_labels)>1:# not leaf-> recurse\n",
    "                next_max_gain = max_gain_node(child_df)\n",
    "                next_max_gain.parent = root\n",
    "                next_max_gain.par_val=att\n",
    "                root.children.append(next_max_gain)\n",
    "                ID3(child_df,depth, root=next_max_gain)\n",
    "        \n",
    "            else:# else if leaf node\n",
    "                leaf = TNode(child_labels[0])\n",
    "                leaf.parent = root\n",
    "                leaf.par_val = att\n",
    "                root.children.append(leaf)\n",
    "                depth =1\n",
    "    else: # Edge case for deep tree\n",
    "        common_label = most_frequent(list(df[list(df.columns)[-1]]))\n",
    "        leaf = TNode(common_label)\n",
    "        root.children = []\n",
    "        root.values = []\n",
    "        leaf.parent = root.parent\n",
    "        leaf.par_val = root.par_val\n",
    "        root.parent.children.remove(root)\n",
    "        root.parent.children.append(leaf)\n",
    "        depth = 1\n",
    "\n",
    "    return root\n",
    "                    \n",
    "# Visualizing decision tree\n",
    "def rep_tree(root,depth=-1):\n",
    "    if len(root.values)==0:#leaf\n",
    "        print('|',root.name,'|')\n",
    "        return\n",
    "    else:\n",
    "        depth +=1\n",
    "        for child in root.children:\n",
    "            print(depth*'\\t',root.name,'=',child.par_val,'->')\n",
    "            rep_tree(child,depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction by ID3 function and binary confusion definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sample through a decision tree\n",
    "def wine_prediction(root,keys,test,labels=None):\n",
    "    try:\n",
    "        if len(root.children)==0:\n",
    "            return root.name\n",
    "        elif root.values[0] == test[keys.index(root.name)]:\n",
    "            return wine_prediction(root.children[0],keys,test,labels)\n",
    "        else:# root.values[1] == test[keys.index(root.name)]:\n",
    "            return wine_prediction(root.children[1],keys,test,labels)\n",
    "    except:\n",
    "        print('e', end =' ' )\n",
    "        return labels[np.random.randint(0,high=len(labels))]\n",
    "\n",
    "       \n",
    "def binary_confusion(GT,y_predicted):\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    for index in range(len(GT)):\n",
    "        if GT[index]=='positive':\n",
    "            if y_predicted[index]=='positive':\n",
    "                TP +=1\n",
    "            else:\n",
    "                FP +=1\n",
    "        else:\n",
    "            if y_predicted[index]=='negative':\n",
    "                TN +=1\n",
    "            else:\n",
    "                FN +=1     \n",
    "    return[[TP,FP],[FN,TN]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a table used to gauge performance of a binary classifier based on true/false positives and negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary split using a threshold \n",
    "for column in wine_df.columns:\n",
    "    if column == 'Class':\n",
    "        break\n",
    "    att = wine_df[column].to_list()\n",
    "    threshhold = np.median(att)\n",
    "    binary_col = [True if a>threshhold else False for a in att]\n",
    "    wine_df[column] = binary_col\n",
    "     \n",
    "def confusion_mat(GT,predicted,labels):\n",
    "    count11,count12,count13 = 0,0,0\n",
    "    count21,count22,count23 = 0,0,0\n",
    "    count31,count32,count33 = 0,0,0\n",
    "\n",
    "    for i in range(len(GT)):\n",
    "        if GT[i]==labels[0]:\n",
    "            if predicted[i] ==labels[0]:\n",
    "                count11 +=1\n",
    "            elif predicted[i] ==labels[1]:\n",
    "                count12 +=1\n",
    "            elif predicted[i] ==labels[2]:\n",
    "                count13 +=1\n",
    "        elif GT[i]==labels[1]:\n",
    "            if predicted[i] ==labels[0]:\n",
    "                count21 +=1\n",
    "            elif predicted[i] ==labels[1]:\n",
    "                count22 +=1\n",
    "            elif predicted[i] ==labels[2]:\n",
    "                count23 +=1\n",
    "        elif GT[i]==labels[2]:\n",
    "            if predicted[i] ==labels[0]:\n",
    "                count31 +=1\n",
    "            elif predicted[i] ==labels[1]:\n",
    "                count32 +=1\n",
    "            elif predicted[i] ==labels[2]:\n",
    "                count33 +=1\n",
    "    return [[count11,count12,count13],\\\n",
    "            [count21,count22,count23],[count31,count32,count33]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding and sampling to ensure random data and running ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_Accuracy,wine_confusion = [] ,[]  \n",
    "d = int(len(wine_df)/10)+1\n",
    "wine_labels  =np.unique(list(wine_df.Class))\n",
    "root = None\n",
    "for times in range(0,10):\n",
    "    Dataset = wine_df.sample(frac=1,random_state=4122020)\n",
    "    #shuffling dataset and random sampling with seed\n",
    "    Folds = [Dataset[:d],\\\n",
    "             Dataset[d:2*d],Dataset[2*d:3*d],Dataset[3*d:4*d],\\\n",
    "             Dataset[4*d:5*d],Dataset[5*d:6*d],Dataset[6*d:7*d],\\\n",
    "             Dataset[7*d:8*d],Dataset[8*d:9*d],\\\n",
    "             Dataset[9*d:]\n",
    "             ]\n",
    "        #10 Folds cross-validation\n",
    "        #Train ID3 based on 90% data and validate result on 10%\n",
    "    for i in np.arange(10):\n",
    "        test_df = Folds[i]\n",
    "        train_df = pd.concat([Folds[i-9],Folds[i-8],Folds[i-7],\\\n",
    "                              Folds[i-6],Folds[i-5],Folds[i-4],\\\n",
    "                              Folds[i-3],Folds[i-2],Folds[i-1]])\n",
    "        root = ID3(train_df)\n",
    "        y_true = test_df[test_df.columns[-1]].to_list()\n",
    "        y_wine_pred = []\n",
    "        for r in range(0,len(test_df)):\n",
    "            test = test_df.iloc[r,:].to_list()\n",
    "            prediction = wine_prediction(root,list(test_df.columns),test,\\\n",
    "                                   labels=wine_labels)\n",
    "            y_wine_pred.append(prediction)\n",
    "\n",
    "        conf = confusion_mat(y_true,y_wine_pred,wine_labels)\n",
    "        if len(y_true)>0:\n",
    "            wine_confusion.append(conf)\n",
    "            wine_Accuracy.append((conf[0][0]+conf[1][1]+conf[2][2])/len(y_true))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating prediction accuracy for ID3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine prediction:\n",
      "Mean(Accuracy)=%91.53, Var(Accuracy)= 0.0046\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d7621b4f3fea>:15: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+alpha)\n",
      "<ipython-input-12-d7621b4f3fea>:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+alpha)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print('Wine prediction:')\n",
    "print('Mean(Accuracy)=%{:.2f}, Var(Accuracy)= {:.4f}'.format(np.mean(wine_Accuracy)*100,np.var(wine_Accuracy)))\n",
    "print('\\nConfusion Matrix:')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(wine_confusion[np.argmax(wine_Accuracy)], cmap='seismic')\n",
    "for (i, j), z in np.ndenumerate(wine_confusion[np.argmax(wine_Accuracy)]):\n",
    "    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "fig.colorbar(cax)\n",
    "alpha = ['Class1', 'Class 2', 'Class3']\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "ax.set_xticklabels(['']+alpha)\n",
    "ax.set_yticklabels(['']+alpha)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     1.000     1.000         4\n",
      "           2      1.000     0.714     0.833         7\n",
      "           3      0.714     1.000     0.833         5\n",
      "\n",
      "    accuracy                          0.875        16\n",
      "   macro avg      0.905     0.905     0.889        16\n",
      "weighted avg      0.911     0.875     0.875        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_wine_pred,digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
